# Assessing Feature Performance

## Introduction

- User problem solved - TARS framework (Feature adoption, retention, satisfaction)
- Business value captured - Hierarchy of business metrics & navigating it
- Final direction - Optimize, redesign, roll back, move on

## User Value

## Feature Adoption (how effectively you surface your feature among target user base)

- What % of the target audience starts using the feature? (Active adopted users / Active target users )
    - adoption → adoption event (they got the value of the feature)
- Using the feature once! → Adoption

Active Target users → Look back at the target user profile (their characteristics, their product behaviour)

### Analyzing & improving feature adoption

Why is feature adoption low?

- Low awareness → Marketing issue!
- Low discoverability within the product -> How to find the feature within the product!!
- High friction to get value from the feature → What are the barriers preventing users from trying & getting value from the feature?  (Simplify the feature, Educate user on the feature's benefits, Onboard users more effectively by creating setup tutorials)
- Low value prop for the user →

### Quantifying Analysis

- Feature usage & performance dashboards & bug reports
- How far user went in the adoption journey in the funnel?
- Segmentation analysis to look at where diff segments are behaving differently

### Qualitative user tools

- User surveys

---

## Feature Retention & Satisfaction

### Feature Retention

- Share of adopted users who continue to use the feature

**Measure Retention Metric**

- Define retention metrics - natural usage frequency of the feature

Retention curve (% of users still active after "n" periods)

- Y axis → % of adopted users who are still active
- X axis → Natural usage frequency intervals

**Reasons why retention is low**

- Feature doesn't meet quality bar - stability issues!
- feature is solving a low-frequency problem - Novelty features which have a diminishing return
- feature isn’t solving the right user problem -

### Feature Satisfaction

- Measuring satisfaction
    - In-product surveys → useful as in-context
    - Embed a feature satisfaction question within a broader product NPS survey
    - qualitative user research,
- Reasons why satisfaction is low
    - Feature Quality - UI/UX, bugs, etc
    

---

## Business value captured

**Navigating hierarchy of metrics**

Output metrics → Topline acquisition, retention & monetization metrics

Input metrics → somewhere in the middle layer of hierarchy!, Serve as inputs to topline business metrics. 

Need to provide the how influencing the input metric will influence the output metric.

**Incremental Impact**

A/B testing → Only difference between control and test groups is our feature

Pre-Post Time series analysis → business value metrics pre & post the feature you launched

**Leading Indicators**

Business value metrics take long time to move, we need early signals

<aside>
💁 To identify leading indicators, it’s often useful to draw out the full hierarchy of metrics, and look at the various inputs to the input and output metrics that we’ve defined.

</aside>